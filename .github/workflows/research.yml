name: research

on:
  workflow_dispatch:
    inputs:
      user_prompt:
        description: "What to research (free text)"
        required: true
        default: "Market analysis: meditation apps and doomscrolling"
      report_type:
        description: "auto|market|competitor|trend|sentiment|ideation|faq"
        required: false
        default: "auto"
      keywords:
        description: "Optional keyword filter"
        required: false
        default: ""

permissions:
  contents: write
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    env:
      DEFAULT_MAX_SUBS: "8"
      DEFAULT_MONTHS: "12"
      DEFAULT_MIN_UPVOTES: "20"
      DEFAULT_LIMIT: "1000"
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r pipeline/requirements.txt

      - name: LLM seed discovery (subreddits & keywords)
        env:
          USER_PROMPT: ${{ inputs.user_prompt }}
          USER_KEYWORDS: ${{ inputs.keywords }}
          DEFAULT_MONTHS: ${{ env.DEFAULT_MONTHS }}
          DEFAULT_MIN_UPVOTES: ${{ env.DEFAULT_MIN_UPVOTES }}
          MAX_SUBS: ${{ env.DEFAULT_MAX_SUBS }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          mkdir -p data
          python pipeline/llm_seed.py \
            --prompt "${USER_PROMPT}" \
            --max-subs ${MAX_SUBS} \
            --default-months ${DEFAULT_MONTHS} \
            --default-min-upvotes ${DEFAULT_MIN_UPVOTES} \
            --out-json data/seed_plan.json \
            --out-subs seed_subs.txt \
            --out-keywords seed_keywords.txt
          python pipeline/process_seed_env.py \
            --seed-json data/seed_plan.json \
            --user-keywords "${USER_KEYWORDS}" \
            --env-json-out data/seed_env.json \
            --env-file "${GITHUB_ENV}"

      - name: Plan (LLM or heuristic)
        env:
          USER_PROMPT: ${{ inputs.user_prompt }}
          REPORT_TYPE: ${{ inputs.report_type || 'auto' }}
          MAX_SUBS: ${{ env.DEFAULT_MAX_SUBS }}
          DEFAULT_MONTHS: ${{ env.DEFAULT_MONTHS }}
          DEFAULT_MIN_UPVOTES: ${{ env.DEFAULT_MIN_UPVOTES }}
          LIMIT: ${{ env.DEFAULT_LIMIT }}
          USER_KEYWORDS: ${{ inputs.keywords }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          REDDIT_CLIENT_ID: ${{ secrets.REDDIT_CLIENT_ID }}
          REDDIT_CLIENT_SECRET: ${{ secrets.REDDIT_CLIENT_SECRET }}
          REDDIT_USER_AGENT: ${{ secrets.REDDIT_USER_AGENT }}
        run: |
          mkdir -p data reports public
          PLAN_MONTHS=${SEED_MONTHS:-${DEFAULT_MONTHS}}
          PLAN_MIN_UPVOTES=${SEED_MIN_UPVOTES:-${DEFAULT_MIN_UPVOTES}}
          python pipeline/llm_planner.py \
            --prompt "${USER_PROMPT}" \
            --report-type "${REPORT_TYPE}" \
            --max-subs ${MAX_SUBS} \
            --default-months ${PLAN_MONTHS} \
            --default-min-upvotes ${PLAN_MIN_UPVOTES} \
            --default-limit ${LIMIT} \
            --keywords "${USER_KEYWORDS}" \
            --seed-subs "${SEED_SUBS}" \
            --seed-keywords-json "${SEED_KEYWORDS_JSON}" \
            --out data/plan.json

          SUBS=$(python -c "import json;print(' '.join(json.load(open('data/plan.json'))['subreddits']))")
          MONTHS_P=$(python -c "import json;print(json.load(open('data/plan.json'))['params']['months'])")
          MIN_UPVOTES_P=$(python -c "import json;print(json.load(open('data/plan.json'))['params']['min_upvotes'])")
          LIMIT_P=$(python -c "import json;print(json.load(open('data/plan.json'))['params']['limit'])")
          REPORT_TYPE_P=$(python -c "import json;print(json.load(open('data/plan.json'))['report_type'])")
          PLAN_KEYWORDS_JSON=$(python -c "import json;print(json.dumps(json.load(open('data/plan.json')).get('filters', {}).get('keywords', []), ensure_ascii=False))")
          PLAN_KEYWORDS=$(python -c "import json;print(' '.join(json.load(open('data/plan.json')).get('filters', {}).get('keywords', [])))")

          echo "SUBS=${SUBS}" >> $GITHUB_ENV
          echo "MONTHS=${MONTHS_P}" >> $GITHUB_ENV
          echo "MIN_UPVOTES=${MIN_UPVOTES_P}" >> $GITHUB_ENV
          echo "LIMIT=${LIMIT_P}" >> $GITHUB_ENV
          echo "REPORT_TYPE=${REPORT_TYPE_P}" >> $GITHUB_ENV
          echo "MAX_SUBS=${MAX_SUBS}" >> $GITHUB_ENV
          echo "SCRAPE_KEYWORDS_JSON=${PLAN_KEYWORDS_JSON}" >> $GITHUB_ENV
          echo "SCRAPE_KEYWORDS=${PLAN_KEYWORDS}" >> $GITHUB_ENV

      - name: Test Reddit API health
        env:
          USER_PROMPT: ${{ inputs.user_prompt }}
          MONTHS: ${{ env.MONTHS }}
          MAX_SUBS: ${{ env.DEFAULT_MAX_SUBS }}
        run: |
          python pipeline/test_reddit_api.py \
            --prompt "${USER_PROMPT}" \
            --keywords-json "${SCRAPE_KEYWORDS_JSON}" \
            --subs "${SUBS}" \
            --months ${MONTHS} \
            --max-subs ${MAX_SUBS}
          echo "Diagnostics:"
          cat data/api_diagnostics.json

      - name: Validate subreddits
        run: |
          python pipeline/validate_subs.py --in data/plan.json --out subs.txt --limit ${MAX_SUBS}
          echo "SUBS=$(cat subs.txt)" >> $GITHUB_ENV
          echo "Validated subs: $(cat subs.txt)"

      - name: Patch plan with validated subs
        run: |
          python pipeline/patch_plan_subs.py --plan data/plan.json --subs-file subs.txt

      - name: Scrape
        run: |
          echo "Using subs: ${SUBS}"
          if [ "${REDDIT_API_STATUS}" = "degraded" ]; then
            echo "WARNING: Reddit API health degraded; scrape may fail due to upstream issues."
          fi
          python pipeline/scrape_reddit.py \
            --subs ${SUBS} \
            --prompt "${{ inputs.user_prompt }}" \
            --months ${MONTHS} \
            --min-upvotes ${MIN_UPVOTES} \
            --limit ${LIMIT} \
            --keywords-json "${SCRAPE_KEYWORDS_JSON}" \
            --out data/raw.jsonl

      - name: Quick count
        run: |
          echo "JSONL lines:"; (wc -l data/raw.jsonl || true)
          echo "First 3 lines:"; (head -n 3 data/raw.jsonl || true)

      - name: Keyword filter (optional)
        if: ${{ env.SCRAPE_KEYWORDS_JSON != '' && env.SCRAPE_KEYWORDS_JSON != '[]' }}
        run: |
          python pipeline/filter_keywords.py \
            --in data/raw.jsonl \
            --out data/raw.jsonl \
            --keywords-json "${SCRAPE_KEYWORDS_JSON}" \
            --mode any

      - name: Analyze
        run: |
          python pipeline/analyze.py \
            --in data/raw.jsonl \
            --out data/analysis.parquet \
            --report reports/pain_map.md

      - name: LLM executive summary (optional)
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          python pipeline/llm_summary.py --plan data/plan.json --analysis data/analysis.parquet --out reports/summary.md || echo "skip"

      - name: Build report
        run: |
          python pipeline/build_report_dynamic.py \
            --plan data/plan.json \
            --pain-map reports/pain_map.md \
            --analysis data/analysis.parquet \
            --summary reports/summary.md \
            --out public/index.html

      - name: Display results snapshot
        run: |
          echo "---- Executive Summary (reports/summary.md) ----"
          (sed -n '1,120p' reports/summary.md || echo "No summary available.")
          echo ""
          echo "---- Raw data sample (data/raw.jsonl) ----"
          (head -n 5 data/raw.jsonl || echo "No raw data available.")

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: public

  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
